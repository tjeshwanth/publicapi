{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dummy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPVXmDVQms5cZfsSgLpTT5U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tjeshwanth/publicapi/blob/master/dummy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5_j7E7xztOM",
        "outputId": "3c7f5d78-79aa-4a0f-be9c-190cff752ebd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.1)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install install-jdk\n",
        "!pip install findspark\n",
        "# import findspark\n",
        "# findspark.init()\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "    # .appName(\"Python Spark SQL basic example\") \\\n",
        "    # .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "     "
      ],
      "metadata": {
        "id": "YVG70Slu2juO"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df = spark.read.option('header',True).csv('/Country.csv')\n",
        "# # df.show()\n",
        "# # df.\n",
        "\n",
        "# # Create RDD from parallelize    \n",
        "# dataList = [(\"Java\", 20000), (\"Python\", 100000), (\"Scala\", 3000)]\n",
        "# # rdd=spark.sparkContext.parallelize(dataList)\n",
        "# # d= spark.sparkContext.parallelize('/Country.csv')\n",
        "# d=spark.sparkContext.parallelize(dataList)\n",
        "\n",
        "# print(type(df))\n",
        "# print(type(d))\n",
        "\n",
        "# dir(pyspark.rdd)\n",
        "# dir(pyspark.sql)\n",
        "# dir(pyspark.sql.dataframe)\n",
        "# data = [('James','','Smith','1991-04-01','M',3000),\n",
        "#   ('Michael','Rose','','2000-05-19','M',4000),\n",
        "#   ('Robert','','Williams','1978-09-05','M',4000),\n",
        "#   ('Maria','Anne','Jones','1967-12-01','F',4000),\n",
        "#   ('Jen','Mary','Brown','1980-02-17','F',-1)\n",
        "# ]\n",
        "\n",
        "# columns = [\"firstname\",\"middlename\",\"lastname\",\"dob\",\"gender\",\"salary\"]\n",
        "# df1 = spark.createDataFrame(data=data, schema = columns)\n",
        "# print(type(df1))\n",
        "# df1.printSchema()\n",
        "# df.printSchema()\n",
        "\n"
      ],
      "metadata": {
        "id": "JyvxaY9E256a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from pyspark.sql.types import StructType,StructField \n",
        "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
        "data = [\n",
        "    ((\"James\",\"\",\"Smith\"),[\"Java\",\"Scala\",\"C++\"],\"OH\",\"M\"),\n",
        "    ((\"Anna\",\"Rose\",\"\"),[\"Spark\",\"Java\",\"C++\"],\"NY\",\"F\"),\n",
        "    ((\"Julia\",\"\",\"Williams\"),[\"CSharp\",\"VB\"],\"OH\",\"F\"),\n",
        "    ((\"Maria\",\"Anne\",\"Jones\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
        "    ((\"Jen\",\"Mary\",\"Brown\"),[\"CSharp\",\"VB\"],\"NY\",\"M\"),\n",
        "    ((\"Mike\",\"Mary\",\"Williams\"),[\"Python\",\"VB\"],\"CA\",\"M\")\n",
        " ]\n",
        "        \n",
        "schema = StructType([\n",
        "     StructField('name', StructType([\n",
        "        StructField('firstname', StringType(), True),\n",
        "        StructField('middlename', StringType(), True),\n",
        "         StructField('lastname', StringType(), True)\n",
        "     ])),\n",
        "     StructField('languages', ArrayType(StringType()), True),\n",
        "     StructField('state', StringType(), True),\n",
        "     StructField('gender', StringType(), True)\n",
        " ])\n",
        "\n",
        "df = spark.createDataFrame(data = data, schema = schema)\n",
        "df.printSchema()\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hPAG8uvnr8d",
        "outputId": "83390926-182e-4fbd-a363-d46fbcca7522"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- name: struct (nullable = true)\n",
            " |    |-- firstname: string (nullable = true)\n",
            " |    |-- middlename: string (nullable = true)\n",
            " |    |-- lastname: string (nullable = true)\n",
            " |-- languages: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- state: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            "\n",
            "+----------------------+------------------+-----+------+\n",
            "|name                  |languages         |state|gender|\n",
            "+----------------------+------------------+-----+------+\n",
            "|{James, , Smith}      |[Java, Scala, C++]|OH   |M     |\n",
            "|{Anna, Rose, }        |[Spark, Java, C++]|NY   |F     |\n",
            "|{Julia, , Williams}   |[CSharp, VB]      |OH   |F     |\n",
            "|{Maria, Anne, Jones}  |[CSharp, VB]      |NY   |M     |\n",
            "|{Jen, Mary, Brown}    |[CSharp, VB]      |NY   |M     |\n",
            "|{Mike, Mary, Williams}|[Python, VB]      |CA   |M     |\n",
            "+----------------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Using equals condition\n",
        "df.filter(df.state == \"OH\").show(truncate=False)\n",
        "\n",
        "# not equals condition\n",
        "df.filter(df.state != \"OH\") \\\n",
        "    .show(truncate=False) \n",
        "df.filter(~(df.state == \"OH\")) \\\n",
        "    .show(truncate=False)\n"
      ],
      "metadata": {
        "id": "qa2jmLnFn5bI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Using startswith\n",
        "df.filter(df.state.startswith(\"N\")).show()\n",
        "\n",
        "\n",
        "#using endswith\n",
        "df.filter(df.state.endswith(\"H\")).show()\n",
        "\n",
        "#contains\n",
        "df.filter(df.state.contains(\"H\")).show()\n",
        "li=[\"OH\",\"CA\",\"DE\"]\n",
        "df.filter(df.state.isin(li)).show()\n",
        "df.filter(~df.state.isin(li)).show()\n",
        "df.filter(df.state.isin(li)==False).show()\n"
      ],
      "metadata": {
        "id": "NXJuhbAdn_Go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = [(2,\"Michael Rose\"),(3,\"Robert Williams\"),\n",
        "     (4,\"Rames Rose\"),(5,\"Rames rose\")\n",
        "  ]\n",
        "df2 = spark.createDataFrame(data = data2, schema = [\"id\",\"name\"])\n",
        "\n",
        "# like - SQL LIKE pattern\n",
        "# df2.filter(df2.name.like(\"%rose%\")).show()\n",
        "# df2.filter(df2.name.rlike(\"(?i)^*rose$\")).show()\n",
        "\n",
        "\n",
        "\n",
        "from pyspark.sql.functions import *\n",
        "frame =  spark.createDataFrame(data = data, schema = schema)\n",
        "\n",
        "# dum =  frame.filter(array_contains(frame.languages,'Java'))\n",
        "# dum.show()\n",
        "# dum.filter(frame.gender=='M').show()\n",
        "\n",
        "frame = df.filter(array_contains(df.languages,'Java'))\n",
        "# dum = frame.filter(df.gender=='M')\n",
        "dum = frame.filter(df.gender=='M') == frame.filter(frame.gender=='M')\n",
        "frame.show()\n",
        "print(end='\\n'*5)\n",
        "# dum.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQHrbGVQoS_w",
        "outputId": "fc36a774-ad89-45cc-ea25-c19b35e9f425"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------------+-----+------+\n",
            "|            name|         languages|state|gender|\n",
            "+----------------+------------------+-----+------+\n",
            "|{James, , Smith}|[Java, Scala, C++]|   OH|     M|\n",
            "|  {Anna, Rose, }|[Spark, Java, C++]|   NY|     F|\n",
            "+----------------+------------------+-----+------+\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "+----------------+------------------+-----+------+\n",
            "|            name|         languages|state|gender|\n",
            "+----------------+------------------+-----+------+\n",
            "|{James, , Smith}|[Java, Scala, C++]|   OH|     M|\n",
            "+----------------+------------------+-----+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9izvmFcjuuuq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}